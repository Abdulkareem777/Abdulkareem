{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "Mobile_Net_V1_CIFAR-100",
      "provenance": [],
      "gpuType": "L4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abdulkareem777/Abdulkareem/blob/main/Mobile_Net_V1_CIFAR_100.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "num_epochs = 100\n",
        "batch_size = 128\n",
        "learning_rate = 0.001"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2023-04-04T08:58:34.744205Z",
          "iopub.execute_input": "2023-04-04T08:58:34.744673Z",
          "iopub.status.idle": "2023-04-04T08:58:38.150912Z",
          "shell.execute_reply.started": "2023-04-04T08:58:34.744588Z",
          "shell.execute_reply": "2023-04-04T08:58:38.149702Z"
        },
        "trusted": true,
        "id": "CyVqFoWS8sFi",
        "outputId": "5739017d-3578-4cf8-9dbb-297905f08b99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize(size=(224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "       (0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)\n",
        "    )\n",
        "])\n",
        "train_dataset = torchvision.datasets.CIFAR100(\n",
        "    root= './data', train = True,\n",
        "    download =True, transform = transform)\n",
        "test_dataset = torchvision.datasets.CIFAR100(\n",
        "    root= './data', train = False,\n",
        "    download =True, transform = transform)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-04T08:58:38.153662Z",
          "iopub.execute_input": "2023-04-04T08:58:38.154535Z",
          "iopub.status.idle": "2023-04-04T08:58:46.151011Z",
          "shell.execute_reply.started": "2023-04-04T08:58:38.154491Z",
          "shell.execute_reply": "2023-04-04T08:58:46.150068Z"
        },
        "trusted": true,
        "id": "wLRIj0nh8sFl",
        "outputId": "35151d14-4cea-4f7e-cacf-8a3453b8019f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 169M/169M [00:13<00:00, 12.8MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-100-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_dataset\n",
        "    , batch_size = batch_size\n",
        "    , shuffle = True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset\n",
        "    , batch_size = batch_size\n",
        "    , shuffle = True)\n",
        "n_total_step = len(train_loader)\n",
        "print(n_total_step)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-04T08:58:46.152585Z",
          "iopub.execute_input": "2023-04-04T08:58:46.152989Z",
          "iopub.status.idle": "2023-04-04T08:58:46.159561Z",
          "shell.execute_reply.started": "2023-04-04T08:58:46.152953Z",
          "shell.execute_reply": "2023-04-04T08:58:46.158342Z"
        },
        "trusted": true,
        "id": "QNfhlUhM8sFn",
        "outputId": "1ce0e136-4c24-4f2f-ff3f-c2cb71d45066",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "391\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch-summary"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-04T08:58:46.162489Z",
          "iopub.execute_input": "2023-04-04T08:58:46.163147Z",
          "iopub.status.idle": "2023-04-04T08:58:57.131841Z",
          "shell.execute_reply.started": "2023-04-04T08:58:46.163112Z",
          "shell.execute_reply": "2023-04-04T08:58:57.130658Z"
        },
        "trusted": true,
        "id": "DuA_R-Wp8sFo",
        "outputId": "81063210-604d-45bc-be58-f66cb4a9d0d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch-summary\n",
            "  Downloading torch_summary-1.4.5-py3-none-any.whl.metadata (18 kB)\n",
            "Downloading torch_summary-1.4.5-py3-none-any.whl (16 kB)\n",
            "Installing collected packages: torch-summary\n",
            "Successfully installed torch-summary-1.4.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-04T08:58:57.134237Z",
          "iopub.execute_input": "2023-04-04T08:58:57.134648Z",
          "iopub.status.idle": "2023-04-04T08:58:57.146812Z",
          "shell.execute_reply.started": "2023-04-04T08:58:57.134607Z",
          "shell.execute_reply": "2023-04-04T08:58:57.145903Z"
        },
        "trusted": true,
        "id": "ELLHmmA28sFp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DepthwiseConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(DepthwiseConvBlock, self).__init__()\n",
        "        self.depthwise_conv = nn.Conv2d(in_channels, in_channels, kernel_size=3, stride=stride, padding=1, groups=in_channels, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
        "        self.pointwise_conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.depthwise_conv(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.pointwise_conv(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x)\n",
        "        return x\n",
        "\n",
        "class MobileNetV1(nn.Module):\n",
        "    def __init__(self, num_classes=100):\n",
        "        super(MobileNetV1, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.features = nn.Sequential(\n",
        "            DepthwiseConvBlock(32, 64, stride=1),\n",
        "            DepthwiseConvBlock(64, 128, stride=2),\n",
        "            DepthwiseConvBlock(128, 128, stride=1),\n",
        "            DepthwiseConvBlock(128, 256, stride=2),\n",
        "            DepthwiseConvBlock(256, 256, stride=1),\n",
        "            DepthwiseConvBlock(256, 512, stride=2),\n",
        "            DepthwiseConvBlock(512, 512, stride=1),\n",
        "            DepthwiseConvBlock(512, 512, stride=1),\n",
        "            DepthwiseConvBlock(512, 512, stride=1),\n",
        "            DepthwiseConvBlock(512, 512, stride=1),\n",
        "            DepthwiseConvBlock(512, 512, stride=1),\n",
        "            DepthwiseConvBlock(512, 1024, stride=2),\n",
        "            DepthwiseConvBlock(1024, 1024, stride=1),\n",
        "        )\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(1024, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.features(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-04T08:58:57.14881Z",
          "iopub.execute_input": "2023-04-04T08:58:57.149228Z",
          "iopub.status.idle": "2023-04-04T08:58:57.16631Z",
          "shell.execute_reply.started": "2023-04-04T08:58:57.149193Z",
          "shell.execute_reply": "2023-04-04T08:58:57.165113Z"
        },
        "trusted": true,
        "id": "IKumBB3r8sFq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = models.vgg16(pretrained = True)\n",
        "# layers = list(model.features.children())\n",
        "# if using pretrained then only train conv5_1, conv5_2, and conv5_3\n",
        "# for l in layers[:-5]:\n",
        "#   for p in l.parameters():\n",
        "#     p.requires_grad = False\n",
        "# layers = list(model.features.children())\n",
        "# if using pretrained then only train conv5_1, conv5_2, and conv5_3\n",
        "# for l in layers[:-5]:\n",
        "#   for p in l.parameters():\n",
        "#     p.requires_grad = False\n",
        "# input_lastLayer = model.classifier[6].in_features\n",
        "# model.classifier[6] = nn.Linear(input_lastLayer,10)\n",
        "model = MobileNetV1().to(device)\n",
        "vgg = model.to(device)\n",
        "print(\"******************************************************************************\")\n",
        "for name, param in vgg.named_parameters():\n",
        "    print(name, param.requires_grad)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate, momentum=0.9,weight_decay=5e-4)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-04T08:58:57.168145Z",
          "iopub.execute_input": "2023-04-04T08:58:57.168552Z",
          "iopub.status.idle": "2023-04-04T08:59:00.557144Z",
          "shell.execute_reply.started": "2023-04-04T08:58:57.168516Z",
          "shell.execute_reply": "2023-04-04T08:59:00.555838Z"
        },
        "trusted": true,
        "id": "v6uqwW4q8sFr",
        "outputId": "15d8c17c-4b58-4226-a463-6382bcd1f249",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "******************************************************************************\n",
            "conv1.weight True\n",
            "bn1.weight True\n",
            "bn1.bias True\n",
            "features.0.depthwise_conv.weight True\n",
            "features.0.bn1.weight True\n",
            "features.0.bn1.bias True\n",
            "features.0.pointwise_conv.weight True\n",
            "features.0.bn2.weight True\n",
            "features.0.bn2.bias True\n",
            "features.1.depthwise_conv.weight True\n",
            "features.1.bn1.weight True\n",
            "features.1.bn1.bias True\n",
            "features.1.pointwise_conv.weight True\n",
            "features.1.bn2.weight True\n",
            "features.1.bn2.bias True\n",
            "features.2.depthwise_conv.weight True\n",
            "features.2.bn1.weight True\n",
            "features.2.bn1.bias True\n",
            "features.2.pointwise_conv.weight True\n",
            "features.2.bn2.weight True\n",
            "features.2.bn2.bias True\n",
            "features.3.depthwise_conv.weight True\n",
            "features.3.bn1.weight True\n",
            "features.3.bn1.bias True\n",
            "features.3.pointwise_conv.weight True\n",
            "features.3.bn2.weight True\n",
            "features.3.bn2.bias True\n",
            "features.4.depthwise_conv.weight True\n",
            "features.4.bn1.weight True\n",
            "features.4.bn1.bias True\n",
            "features.4.pointwise_conv.weight True\n",
            "features.4.bn2.weight True\n",
            "features.4.bn2.bias True\n",
            "features.5.depthwise_conv.weight True\n",
            "features.5.bn1.weight True\n",
            "features.5.bn1.bias True\n",
            "features.5.pointwise_conv.weight True\n",
            "features.5.bn2.weight True\n",
            "features.5.bn2.bias True\n",
            "features.6.depthwise_conv.weight True\n",
            "features.6.bn1.weight True\n",
            "features.6.bn1.bias True\n",
            "features.6.pointwise_conv.weight True\n",
            "features.6.bn2.weight True\n",
            "features.6.bn2.bias True\n",
            "features.7.depthwise_conv.weight True\n",
            "features.7.bn1.weight True\n",
            "features.7.bn1.bias True\n",
            "features.7.pointwise_conv.weight True\n",
            "features.7.bn2.weight True\n",
            "features.7.bn2.bias True\n",
            "features.8.depthwise_conv.weight True\n",
            "features.8.bn1.weight True\n",
            "features.8.bn1.bias True\n",
            "features.8.pointwise_conv.weight True\n",
            "features.8.bn2.weight True\n",
            "features.8.bn2.bias True\n",
            "features.9.depthwise_conv.weight True\n",
            "features.9.bn1.weight True\n",
            "features.9.bn1.bias True\n",
            "features.9.pointwise_conv.weight True\n",
            "features.9.bn2.weight True\n",
            "features.9.bn2.bias True\n",
            "features.10.depthwise_conv.weight True\n",
            "features.10.bn1.weight True\n",
            "features.10.bn1.bias True\n",
            "features.10.pointwise_conv.weight True\n",
            "features.10.bn2.weight True\n",
            "features.10.bn2.bias True\n",
            "features.11.depthwise_conv.weight True\n",
            "features.11.bn1.weight True\n",
            "features.11.bn1.bias True\n",
            "features.11.pointwise_conv.weight True\n",
            "features.11.bn2.weight True\n",
            "features.11.bn2.bias True\n",
            "features.12.depthwise_conv.weight True\n",
            "features.12.bn1.weight True\n",
            "features.12.bn1.bias True\n",
            "features.12.pointwise_conv.weight True\n",
            "features.12.bn2.weight True\n",
            "features.12.bn2.bias True\n",
            "fc.weight True\n",
            "fc.bias True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_loss = np.inf\n",
        "patience = 5\n",
        "counter = 0\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (imgs , labels) in enumerate(train_loader):\n",
        "      imgs = imgs.to(device)\n",
        "      labels = labels.to(device)\n",
        "      labels_hat = model(imgs)\n",
        "      n_corrects = (labels_hat.argmax(axis=1)==labels).sum().item()\n",
        "      loss_value = criterion(labels_hat, labels)\n",
        "      loss_value.backward()\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "      if (i+1) % 250 == 0:\n",
        "        print(f'epoch {epoch+1}/{num_epochs}, step: {i+1}/{n_total_step}: loss = {loss_value:.5f}, acc = {100*(n_corrects/labels.size(0)):.2f}%')\n",
        "        print()\n",
        "    print('val')\n",
        "    with torch.no_grad():\n",
        "      number_corrects = 0\n",
        "      number_samples = 0\n",
        "      val_loss = 0\n",
        "      for i, (test_images_set , test_labels_set) in enumerate(test_loader):\n",
        "          test_images_set = test_images_set.to(device)\n",
        "          test_labels_set = test_labels_set.to(device)\n",
        "\n",
        "          y_predicted = model(test_images_set)\n",
        "          val_loss += criterion(y_predicted, test_labels_set)\n",
        "          labels_predicted = y_predicted.argmax(axis = 1)\n",
        "          number_corrects += (labels_predicted==test_labels_set).sum().item()\n",
        "          number_samples += test_labels_set.size(0)\n",
        "      print(f'Overall accuracy {(number_corrects / number_samples)*100}%')\n",
        "      # Update the best loss and the counter\n",
        "      if val_loss < best_loss:\n",
        "        best_loss = val_loss\n",
        "        counter = 0\n",
        "        # Save the best model weights\n",
        "        torch.save(model, 'best_model.pth.tar')\n",
        "      else:\n",
        "        counter += 1\n",
        "\n",
        "      # Check if the patience has been exceeded\n",
        "    if counter >= patience:\n",
        "      print('Early stopping!')\n",
        "      break\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-04T08:59:00.560271Z",
          "iopub.execute_input": "2023-04-04T08:59:00.560569Z",
          "iopub.status.idle": "2023-04-04T10:25:16.999474Z",
          "shell.execute_reply.started": "2023-04-04T08:59:00.560542Z",
          "shell.execute_reply": "2023-04-04T10:25:16.99839Z"
        },
        "trusted": true,
        "id": "t5aNVoFK8sFs",
        "outputId": "d99e51df-e6f9-46ce-a009-a71466f27033",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1/100, step: 250/391: loss = 4.47857, acc = 5.47%\n",
            "\n",
            "val\n",
            "Overall accuracy 3.1399999999999997%\n",
            "epoch 2/100, step: 250/391: loss = 4.30964, acc = 3.12%\n",
            "\n",
            "val\n",
            "Overall accuracy 5.08%\n",
            "epoch 3/100, step: 250/391: loss = 4.08243, acc = 7.03%\n",
            "\n",
            "val\n",
            "Overall accuracy 7.46%\n",
            "epoch 4/100, step: 250/391: loss = 3.98204, acc = 8.59%\n",
            "\n",
            "val\n",
            "Overall accuracy 8.58%\n",
            "epoch 5/100, step: 250/391: loss = 3.90873, acc = 10.16%\n",
            "\n",
            "val\n",
            "Overall accuracy 10.33%\n",
            "epoch 6/100, step: 250/391: loss = 3.93912, acc = 15.62%\n",
            "\n",
            "val\n",
            "Overall accuracy 12.15%\n",
            "epoch 7/100, step: 250/391: loss = 3.67286, acc = 10.94%\n",
            "\n",
            "val\n",
            "Overall accuracy 13.19%\n",
            "epoch 8/100, step: 250/391: loss = 3.61384, acc = 13.28%\n",
            "\n",
            "val\n",
            "Overall accuracy 15.49%\n",
            "epoch 9/100, step: 250/391: loss = 3.35933, acc = 17.97%\n",
            "\n",
            "val\n",
            "Overall accuracy 16.85%\n",
            "epoch 10/100, step: 250/391: loss = 3.41100, acc = 19.53%\n",
            "\n",
            "val\n",
            "Overall accuracy 18.77%\n",
            "epoch 11/100, step: 250/391: loss = 3.30442, acc = 18.75%\n",
            "\n",
            "val\n",
            "Overall accuracy 19.67%\n",
            "epoch 12/100, step: 250/391: loss = 2.91533, acc = 28.91%\n",
            "\n",
            "val\n",
            "Overall accuracy 22.18%\n",
            "epoch 13/100, step: 250/391: loss = 3.30224, acc = 18.75%\n",
            "\n",
            "val\n",
            "Overall accuracy 23.34%\n",
            "epoch 14/100, step: 250/391: loss = 3.05793, acc = 24.22%\n",
            "\n",
            "val\n",
            "Overall accuracy 24.03%\n",
            "epoch 15/100, step: 250/391: loss = 2.67968, acc = 32.03%\n",
            "\n",
            "val\n",
            "Overall accuracy 25.34%\n",
            "epoch 16/100, step: 250/391: loss = 2.98631, acc = 20.31%\n",
            "\n",
            "val\n",
            "Overall accuracy 26.919999999999998%\n",
            "epoch 17/100, step: 250/391: loss = 2.89888, acc = 22.66%\n",
            "\n",
            "val\n",
            "Overall accuracy 27.62%\n",
            "epoch 18/100, step: 250/391: loss = 2.52013, acc = 34.38%\n",
            "\n",
            "val\n",
            "Overall accuracy 29.060000000000002%\n",
            "epoch 19/100, step: 250/391: loss = 2.68179, acc = 27.34%\n",
            "\n",
            "val\n",
            "Overall accuracy 30.2%\n",
            "epoch 20/100, step: 250/391: loss = 2.58270, acc = 34.38%\n",
            "\n",
            "val\n",
            "Overall accuracy 31.240000000000002%\n",
            "epoch 21/100, step: 250/391: loss = 2.28467, acc = 36.72%\n",
            "\n",
            "val\n",
            "Overall accuracy 32.1%\n",
            "epoch 22/100, step: 250/391: loss = 2.42197, acc = 35.94%\n",
            "\n",
            "val\n",
            "Overall accuracy 33.7%\n",
            "epoch 23/100, step: 250/391: loss = 2.42187, acc = 36.72%\n",
            "\n",
            "val\n",
            "Overall accuracy 34.08%\n",
            "epoch 24/100, step: 250/391: loss = 1.96874, acc = 48.44%\n",
            "\n",
            "val\n",
            "Overall accuracy 35.099999999999994%\n",
            "epoch 25/100, step: 250/391: loss = 1.91189, acc = 50.78%\n",
            "\n",
            "val\n",
            "Overall accuracy 35.15%\n",
            "epoch 26/100, step: 250/391: loss = 1.91890, acc = 51.56%\n",
            "\n",
            "val\n",
            "Overall accuracy 35.64%\n",
            "epoch 27/100, step: 250/391: loss = 1.73868, acc = 56.25%\n",
            "\n",
            "val\n",
            "Overall accuracy 35.97%\n",
            "epoch 28/100, step: 250/391: loss = 1.81379, acc = 51.56%\n",
            "\n",
            "val\n",
            "Overall accuracy 36.82%\n",
            "epoch 29/100, step: 250/391: loss = 1.64133, acc = 52.34%\n",
            "\n",
            "val\n",
            "Overall accuracy 37.3%\n",
            "epoch 30/100, step: 250/391: loss = 1.53235, acc = 53.91%\n",
            "\n",
            "val\n",
            "Overall accuracy 37.74%\n",
            "epoch 31/100, step: 250/391: loss = 1.50943, acc = 61.72%\n",
            "\n",
            "val\n",
            "Overall accuracy 37.31%\n",
            "epoch 32/100, step: 250/391: loss = 1.59609, acc = 53.12%\n",
            "\n",
            "val\n",
            "Overall accuracy 38.16%\n",
            "epoch 33/100, step: 250/391: loss = 1.61551, acc = 58.59%\n",
            "\n",
            "val\n",
            "Overall accuracy 38.12%\n",
            "epoch 34/100, step: 250/391: loss = 1.61614, acc = 57.03%\n",
            "\n",
            "val\n",
            "Overall accuracy 38.550000000000004%\n",
            "epoch 35/100, step: 250/391: loss = 1.29448, acc = 64.06%\n",
            "\n",
            "val\n",
            "Overall accuracy 38.53%\n",
            "epoch 36/100, step: 250/391: loss = 1.07672, acc = 71.09%\n",
            "\n",
            "val\n",
            "Overall accuracy 38.279999999999994%\n",
            "epoch 37/100, step: 250/391: loss = 1.16876, acc = 71.09%\n",
            "\n",
            "val\n",
            "Overall accuracy 39.019999999999996%\n",
            "Early stopping!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    number_corrects = 0\n",
        "    number_samples = 0\n",
        "    for i, (test_images_set , test_labels_set) in enumerate(test_loader):\n",
        "        test_images_set = test_images_set.to(device)\n",
        "        test_labels_set = test_labels_set.to(device)\n",
        "\n",
        "        y_predicted = model(test_images_set)\n",
        "        labels_predicted = y_predicted.argmax(axis = 1)\n",
        "        number_corrects += (labels_predicted==test_labels_set).sum().item()\n",
        "        number_samples += test_labels_set.size(0)\n",
        "    print(f'Overall accuracy {(number_corrects / number_samples)*100}%')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-04T10:25:17.000987Z",
          "iopub.execute_input": "2023-04-04T10:25:17.001986Z",
          "iopub.status.idle": "2023-04-04T10:25:49.158274Z",
          "shell.execute_reply.started": "2023-04-04T10:25:17.001945Z",
          "shell.execute_reply": "2023-04-04T10:25:49.157183Z"
        },
        "trusted": true,
        "id": "gqC5nJXm8sFt",
        "outputId": "6cce7308-2f1d-4747-8bef-4180eac938a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall accuracy 39.290000000000006%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, 'model.pth.tar')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-04T10:41:09.593765Z",
          "iopub.execute_input": "2023-04-04T10:41:09.594138Z",
          "iopub.status.idle": "2023-04-04T10:41:09.653069Z",
          "shell.execute_reply.started": "2023-04-04T10:41:09.594106Z",
          "shell.execute_reply": "2023-04-04T10:41:09.65211Z"
        },
        "trusted": true,
        "id": "2ph1bGbA8sFu"
      },
      "execution_count": 10,
      "outputs": []
    }
  ]
}